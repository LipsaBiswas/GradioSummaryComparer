# -*- coding: utf-8 -*-
"""GradioTestApp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16_DX0LvG8uS_S9pVFsDXT6-vj1m9vnyK
"""

# !pip install -q gradio

# !pip install -q transformers

# !pip install -q sentencepiece

# !pip install -q bert-extractive-summarizer

# !pip install -q  sumy

import gradio as gr
import transformers
import sentencepiece
from summarizer import Summarizer
# import sumy
# import nltk
# nltk.download('punkt')

# from sumy.parsers.html import HtmlParser
# from sumy.parsers.plaintext import PlaintextParser
# from sumy.nlp.tokenizers import Tokenizer
# from sumy.summarizers.text_rank import TextRankSummarizer
# from sumy.summarizers.lex_rank import LexRankSummarizer
# from sumy.summarizers.luhn import LuhnSummarizer
# from sumy.summarizers.lsa import LsaSummarizer
# from sumy.summarizers.kl import KLSummarizer
# from sumy.summarizers.edmundson import EdmundsonSummarizer
# from sumy.summarizers.random import  RandomSummarizer
# from sumy.summarizers.reduction import  ReductionSummarizer
# from sumy.summarizers.sum_basic import  SumBasicSummarizer
# from sumy.nlp.stemmers import Stemmer
# from sumy.utils import get_stop_words

# LANGUAGE= 'english'
# SENTENCES_COUNT =2
# stemmer = Stemmer(LANGUAGE)



bert_model=Summarizer()

# !pip install -q keybert

def SummariseText(inp,no_of_sentences,key_words_inp):
   
    
  generated_text1_Gensim_50pc="";
  generated_text2_Gensim_20pc="";
  generated_text3_TextRankSummarizer ="";
  generated_text4_LexRankSummarizer="";
  generated_text5_LuhnSummarizer ="";
  generated_text6_LsaSummarizer="";
  generated_text7_KLSummarizer ="";
  generated_text8_RandomSummarizer="";
  generated_text9_ReductionSummarizer =""; 
  generated_text10_SumBasicSummarizer =""; 
  generated_text11_Edmundson =""; 
  generated_text12_bertmodel ="";
  generated_text13_transformer_pipeline="";
  generated_text14_t5_base =""; 
  generated_text15_t5_small =""; 
  generated_text16_finetuned_summarize_news =""; 
  extracted_keywords="";
  
  # generated_text1_Gensim_50pc = summarize(inp, ratio=0.5)  
  # generated_text2_Gensim_20pc = summarize(inp, ratio=0.2)
  # num_sentences_in_summary = no_of_sentences #getting 2 sentence
  # parser = PlaintextParser(inp, Tokenizer('english'))
  # summarizer_list=("TextRankSummarizer","LexRankSummarizer","LuhnSummarizer","LsaSummarizer","KLSummarizer","RandomSummarizer","ReductionSummarizer","SumBasicSummarizer") #list of summarizers
  # summarizers = [TextRankSummarizer(), LexRankSummarizer(), LuhnSummarizer(), LsaSummarizer(),KLSummarizer(),RandomSummarizer(),ReductionSummarizer(),SumBasicSummarizer()]
  # all_sentences= "";
  # for i,summarizer in enumerate(summarizers):
  #   summary_text =""
    
  #   for sentence in summarizer(parser.document, num_sentences_in_summary):
  #        summary_text = summary_text + str(sentence)
  #   if (summarizer_list[i]=="TextRankSummarizer"):
  #     generated_text3_TextRankSummarizer = summary_text
  #   elif (summarizer_list[i]=="LexRankSummarizer"):
  #     generated_text4_LexRankSummarizer = summary_text
  #   elif (summarizer_list[i]=="LuhnSummarizer"):
  #     generated_text5_LuhnSummarizer = summary_text
  #   elif (summarizer_list[i]=="LsaSummarizer"):
  #     generated_text6_LsaSummarizer = summary_text
  #   elif (summarizer_list[i]=="KLSummarizer"):
  #     generated_text7_KLSummarizer = summary_text
  #   elif (summarizer_list[i]=="RandomSummarizer"):
  #     generated_text8_RandomSummarizer = summary_text
  #   elif (summarizer_list[i]=="ReductionSummarizer"):
  #     generated_text9_ReductionSummarizer = summary_text
  #   elif (summarizer_list[i]=="SumBasicSummarizer"):
  #     generated_text10_SumBasicSummarizer= summary_text
  #   else  :
  #     generated_text1999="";
  
  # EdSummarizer = EdmundsonSummarizer(stemmer)
  # EdSummarizer.bonus_words = key_words_inp ;
  # # ('amplification-free', 'fluorescence-based','Hybrid', 'Capture' ,'Fluorescence', 'Immunoassay')
  # EdSummarizer.stigma_words = ('example')
  # EdSummarizer.null_words = ('literature','however')
  # parser = PlaintextParser(inp, Tokenizer('english'))
  # for sentence in EdSummarizer(parser.document , SENTENCES_COUNT):
  #     generated_text11_Edmundson += str(sentence)
      
  generated_text12_bertmodel = bert_model(inp)

   
 

  # return extracted_keywords,generated_text1_Gensim_50pc,generated_text2_Gensim_20pc,generated_text3_TextRankSummarizer,generated_text4_LexRankSummarizer,generated_text5_LuhnSummarizer,generated_text6_LsaSummarizer,generated_text7_KLSummarizer,generated_text8_RandomSummarizer,generated_text9_ReductionSummarizer,generated_text10_SumBasicSummarizer,generated_text11_Edmundson,generated_text12_bertmodel,generated_text13_transformer_pipeline,generated_text14_t5_base,generated_text15_t5_small,generated_text16_finetuned_summarize_news,generated_text17_of_summaries1
  return   generated_text12_bertmodel

iface = gr.Interface(
  fn=SummariseText, 
  inputs=[gr.inputs.Textbox(label="Abstract (*Enter paragraphs)",lines=10, placeholder="Enter abstract text here..."),
          gr.inputs.Textbox(label="No. of sentences for summary", placeholder="Enter a number between 2 to 4"),
          gr.inputs.Textbox(label="Input keywords(ex. 'COVID-19', 'Repurposing', 'Renin')",lines=3, placeholder="eg ('COVID-19', 'Repurposing', 'Renin')") ],
    
  outputs=[ 
           gr.outputs.Textbox(label="* Summary-12 (Bert) ")  ],title= "Auto summarization and Summary comparision(beta)"  )
iface.launch(debug=True)