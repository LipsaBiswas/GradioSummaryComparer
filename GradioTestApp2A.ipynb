{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GradioTestApp2A.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO2ylyvREWxe+Hwvby4EYft",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LipsaBiswas/GradioSummaryComparer/blob/main/GradioTestApp2A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qwta8LWfBYw"
      },
      "source": [
        "# !pip install -q gradio\n",
        "# !pip install -q transformers\n",
        "# !pip install -q sentencepiece\n",
        "# !pip install -q bert-extractive-summarizer \n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaCZJc2cfYtK"
      },
      "source": [
        "import gradio as gr\n",
        "import transformers\n",
        "import sentencepiece\n",
        "from summarizer import Summarizer\n",
        "# from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from transformers import pipeline\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMsf66svtyuj"
      },
      "source": [
        "# from parrot import Parrot"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq7KHPu5ulEM"
      },
      "source": [
        "# parrot = Parrot(model_tag=\"prithivida/parrot_paraphraser_on_T5\", use_gpu=False)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0iAWFtYknEX"
      },
      "source": [
        "def GenerateModelTokenizer_summary(inp,pretrained_model_selected,max_pct):\n",
        "   \n",
        "    summary_generated=\"\" \n",
        "    pretrained_model_selected = pretrained_model_selected.lower()\n",
        "    try:\n",
        "      if pretrained_model_selected==\"bert\":\n",
        "        bert_model=Summarizer()\n",
        "        summary_generated = bert_model(inp)\n",
        "      elif pretrained_model_selected==\"google/pegasus-pubmed\" or pretrained_model_selected=='google/pegasus-xsum' or pretrained_model_selected==\"mayu0007/pegasus_large_covid\"or pretrained_model_selected==\"google/pegasus-wikihow\" or pretrained_model_selected==\"deep-learning-analytics/wikihow-t5-small\":\n",
        "        \n",
        "        # model = AutoModelForSeq2SeqLM.from_pretrained(pretrained_model_selected)\n",
        "        # tokenizer = AutoTokenizer.from_pretrained(pretrained_model_selected)\n",
        "        # inputs = tokenizer.encode(\"summarize: \" + inp, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "        # outputs = model.generate(\n",
        "        #   inputs, \n",
        "        #   max_length=max_length, \n",
        "        #   min_length=50, \n",
        "        #   length_penalty=2.0, \n",
        "        #   num_beams=4, \n",
        "        #   early_stopping=True)\n",
        "        # summary_generated=tokenizer.decode(outputs[0])\n",
        "\n",
        "        summarizer = pipeline(\"summarization\", model=pretrained_model_selected) \n",
        "        if (max_pct > 0):\n",
        "          summary=summarizer(inp,max_length =int((max_pct/100) * len(inp)))\n",
        "        else:\n",
        "          summary=summarizer(inp)\n",
        "        # summary=summarizer(inp ,min_length = int(0.3 * len(inp)), max_length =int(0.3 * len(inp)))\n",
        "        summary_generated= summary[0]['summary_text']\n",
        "        \n",
        "      else:\n",
        "        summary_generated=\" No summary generated, please check with the admin\"\n",
        "    except Exception as e:\n",
        "        summary_generated=\" Error occured, please check with the admin: \"+ str(e)\n",
        "    # paraphrased_summary_generated = parrot.augment(input_phrase=summary_generated)\n",
        "    paraphrased_summary_generated =\"Not implemented, check with admin\" \n",
        "    return summary_generated,paraphrased_summary_generated\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT7Edl1cGn2u"
      },
      "source": [
        "# pip install git+https://github.com/PrithivirajDamodaran/Parrot_Paraphraser.git\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13Oa4AarG0O2"
      },
      "source": [
        "\n",
        "#Init models (make sure you init ONLY once if you integrate this to your code)\n",
        "# parrot = Parrot(model_tag=\"prithivida/parrot_paraphraser_on_T5\", use_gpu=False)\n",
        "\n",
        "# phrases = [\"Can you recommed some upscale restaurants in Newyork?\",\n",
        "#            \"What are the famous places we should not miss in Russia?\"\n",
        "# ]\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN_heafBJTPU"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URozdhSpgIVF"
      },
      "source": [
        "def SummarizeText(inp, pretrained_model_selected, max_pct):\n",
        "   \n",
        "  summary_generated,paraphrased_summary_generated=GenerateModelTokenizer_summary(inp,pretrained_model_selected,max_pct)\n",
        "  original_text_length = wordCount(inp)\n",
        "  summary_text_length = wordCount(summary_generated)\n",
        "  return summary_generated ,original_text_length,summary_text_length,paraphrased_summary_generated"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ogP2ZrJoVtf"
      },
      "source": [
        "def wordCount(stringinput):\n",
        "  word_list = stringinput.split()\n",
        "  number_of_words = len(word_list)\n",
        "  return number_of_words;\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WBEpB6aHfk6_",
        "outputId": "3fe28df4-7308-472e-ce23-d065ea92fb09"
      },
      "source": [
        "iface = gr.Interface(\n",
        "  fn=SummarizeText, \n",
        "  inputs=[gr.inputs.Textbox(label=\"Abstract (*Enter paragraphs)\",lines=20, placeholder=\"Enter abstract text here...\") ,\n",
        "          gr.inputs.Radio([\"deep-learning-analytics/wikihow-t5-small\",\"Bert\", \"google/pegasus-pubmed\", \"mayu0007/pegasus_large_covid\",\"google/pegasus-wikihow\",\"google/pegasus-xsum\"]),\n",
        "          gr.inputs.Slider(0, 70,step=10,label=\"Max - % of original text(better NOT to change)\")\n",
        "        ],\n",
        "    \n",
        "  outputs=[\n",
        "           gr.outputs.Textbox(label=\" Summary\"),\n",
        "           gr.outputs.Textbox(label=\" Original abstract text word count\"),\n",
        "           gr.outputs.Textbox(label=\" Summary text word count\"),\n",
        "           gr.outputs.Textbox(label=\" Paraphrased Summary\")],title= \"Auto summarization and Summary comparision(beta)\"  )\n",
        "iface.launch(debug=False)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "This share link will expire in 24 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted (NEW!)\n",
            "Running on External URL: https://29840.gradio.app\n",
            "Interface loading below...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://29840.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f300ca03110>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-c762d58e89c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m            \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" Summary text word count\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m            gr.outputs.Textbox(label=\" Paraphrased Summary\")],title= \"Auto summarization and Summary comparision(beta)\"  )\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0miface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gradio/interface.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, auth, auth_message, private_endpoint, prevent_thread_lock)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0mis_in_interactive_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ps1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprevent_thread_lock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_in_interactive_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOKtwOavmQ0b"
      },
      "source": [
        "a ='''\n",
        "Severe Acute Respiratory Syndrome Coronavirus-2 (SARS-CoV-2), causing Coronavirus Disease 19 (COVID-19), emerged at the end of 2019 and quickly spread to cause a global pandemic with severe socio-economic consequences. The early sequencing of its RNA genome revealed its high similarity to SARS, likely to have originated from bats. The SARS-CoV-2 non-structural protein 10 (nsp10) displays high sequence similarity with its SARS homologue, which binds to and stimulates the 3'-to-5' exoribonuclease and the 2'-O-methlytransferase activities of nsps 14 and 16, respectively. Here, we report the biophysical characterization and 1.6 Å resolution structure of the unbound form of nsp10 from SARS-CoV-2 and compare it to the structures of its SARS homologue and the complex-bound form with nsp16 from SARS-CoV-2. The crystal structure and solution behaviour of nsp10 will not only form the basis for understanding the role of SARS-CoV-2 nsp10 as a central player of the viral RNA capping apparatus, but will also serve as a basis for the development of inhibitors of nsp10, interfering with crucial functions of the replication-transcription complex and virus replication\n",
        "'''\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCzyE29JoX_w"
      },
      "source": [
        "# SummarizeText(a,\"google/pegasus-pubmed\")"
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}